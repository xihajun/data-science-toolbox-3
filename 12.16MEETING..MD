
## SOMETHING TO READ: 
1.Random Forests provide free cross-validation 2.why `reduce("+",summary_matrices)` <br>
FROM: https://stats.stackexchange.com/questions/345263/classification-threshold-selection-for-predictions-on-unseen-data<br>
I have two remarks, which do not answer your question:<br>
1. when you train a RF model you do not need to perform cross validation: https://datascience.stackexchange.com/questions/6510/does-modeling-with-random-forests-requre-cross-validation <br>
2. which threshold you choose has nothing to do with statistics, it is a decision you need to take depending on the problem at hand (this is a really nice answer): Classification probability threshold<br>
So I guess this second point helps me to rephrase your question: assuming that I want to maximize the F1 score also in the unseen data (test set), which threshold should I use, the one maximising the F1 score in the cross validation or in the training?<br>
I think the one in the training. Because cross validation just helps you choose/validate the model. Also I do not expect the two thresholds should differ much in absence of overfitting. <br>

## SMOTE:  https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3648438/
![1471-2105-14-106-5](https://user-images.githubusercontent.com/25631641/50048174-0ee1aa80-00bd-11e9-878a-8fe4d2543001.jpg)
FROM: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3648438/

